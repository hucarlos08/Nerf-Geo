{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing Light: The Pinhole Camera Model \n",
    "To create images from our 3D representations, we need to understand how cameras capture light. The pinhole camera model is a simple yet powerful way to describe this process. Imagine a box with a tiny hole on one side (the pinhole) and a light-sensitive surface (the image plane) on the opposite side. Light rays from the 3D world pass through the pinhole and project an inverted image onto the image plane.\n",
    "\n",
    "| ![2d-train](https://imgur.com/4hoTcNA.png) |\n",
    "| :---: |\n",
    "| **Figure 1**: Pinhole camera. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Model\n",
    "Coordinate Systems: We'll use two coordinate systems:\n",
    "\n",
    "1. World Coordinates: $(x_w, y_w, z_w)$ to describe points in the 3D world.\n",
    "2. Image Coordinates: $(x, y)$ to describe points on the 2D image plane.\n",
    "3. Pinhole (Center of Projection):  Located at the origin of the world coordinates $(0, 0, 0)$.\n",
    "4. Image Plane: Located at a distance f (focal length) along the Z-axis, with the center at $(0, 0, f)$.\n",
    "5. Projection: A 3D point $P = (x_w, y_w, z_w)$ is projected onto the image plane at point $p = (x, y)$ through the pinhole.\n",
    "\n",
    "\n",
    "The idea is to understand how to perform transformations between each of the frames.\n",
    "\n",
    "| ![2d-train](https://imgur.com/EvLTR2w.png) |\n",
    "| :---: |\n",
    "| **Figure 2**: Camera model. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From World to Camera\n",
    "\n",
    "### World Coordinates\n",
    "We usually represent the **world** coordinates using a vector $\\mathbf{X}_w\\in\\mathbb{R}^3$ defined as:\n",
    "$$\n",
    "\\mathbf{X}_w=\\begin{bmatrix}\n",
    "x_w \\\\\n",
    "y_w \\\\\n",
    "z_w\n",
    "\\end{bmatrix}\n",
    "$$.\n",
    "\n",
    "### Camera Coordinates\n",
    "This is a dynamic reference frame that moves as we move the camera to take pictures. If a point $P$ has coordinates $\\mathbf{X}_w$ in the *world frame*, in the **camera frame** we assign the coordinates:\n",
    "$$\n",
    "\\mathbf{X}_c=\\begin{bmatrix}\n",
    "x_c \\\\\n",
    "y_c \\\\\n",
    "z_c\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**The location of point $P$ does not change. Only the way we look at the point changes with the change in the camera's reference frame.**\n",
    "\n",
    "### Coordinate Transformation\n",
    "It is possible to transform the coordinates of point $P$ from world to camera using the following equation:\n",
    "$$\n",
    "\\mathbf{X}_c=R\\times(\\mathbf{X}_w-\\mathbf{C}_w),\n",
    "$$\n",
    "where:\n",
    "1. $R$ is a matrix representing the **orientation** of the camera with respect to the *world* coordinates.\n",
    "2. $\\mathbf{C}_w$ is a vector representing the **position** of the camera with respect to the *world* coordinates.\n",
    "\n",
    "The matrix $C_{ext}$ is known as **extrinsic parameter matrix** because it represents the rotation and translation values, which are external properties of the camera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Formation\n",
    "\n",
    "Let's return to the reference frames of the camera and the image\n",
    "\n",
    "| ![2d-train](https://imgur.com/GCMmOLa.png) |\n",
    "| :---: |\n",
    "| **Figure 1**: Modelo proyectivo. |\n",
    "\n",
    "\n",
    "### Projection to Image Plane\n",
    "The projection to the image plane is done using the intrinsic parameters of the camera. If a point $P$ has coordinates $\\mathbf{X}_c$ in the camera frame, its projection onto the image plane is given by:\n",
    "$$\n",
    "\\begin{align}\n",
    "x_i=f\\frac{x_c}{z_c} \\\\\n",
    "y_i=f\\frac{y_c}{z_c}\n",
    "\\end{align}\n",
    "$$\n",
    "It is common for the image origin to be the top-left corner, so it is convenient to add offsets with respect to the image plane center:\n",
    "$$\n",
    "\\begin{align}\n",
    "x_i=f\\frac{x_c}{z_c}+\\delta_x \\\\\n",
    "y_i=f\\frac{y_c}{z_c}+\\delta_y\n",
    "\\end{align}\n",
    "$$\n",
    "We can rewrite the previous equations as:\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "fx_c+ z_c\\delta_x\\\\\n",
    "fy_c+ z_c\\delta_y\\\\\n",
    "~z_c\\\\\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "f_x&0&\\delta_x&0\\\\\n",
    "0&f_y&\\delta_y&0\\\\\n",
    "0&0&1&0\\\\\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{c}\\\\\n",
    "y_{c}\\\\\n",
    "z_{c}\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "The first matrix on the right-hand side of the equation is known as the intrinsic parameters matrix $K$. It is termed intrinsic because it includes the focal length $f$ and the image plane center, which are internal properties of the camera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLAPSED\n",
    "import torch\n",
    "\n",
    "from nerfstudio.cameras.cameras import Cameras, CameraType\n",
    "from nerfstudio.utils import plotly_utils as vis\n",
    "\n",
    "cx = 20.0\n",
    "cy = 10.0\n",
    "fx = 10.0\n",
    "fy = 20.0\n",
    "\n",
    "PERSPECTIVE = CameraType.PERSPECTIVE\n",
    "FISHEYE = CameraType.FISHEYE\n",
    "\n",
    "c2w = torch.eye(4)[None, :3, :]\n",
    "\n",
    "camera = Cameras(fx=fx, fy=fy, cx=cx, cy=cy, camera_to_worlds=c2w, camera_type=FISHEYE)\n",
    "fig = vis.vis_camera_rays(camera)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "\n",
    "from nerfstudio.cameras.cameras import Cameras, CameraType\n",
    "from nerfstudio.utils import plotly_utils as vis\n",
    "\n",
    "# OUTPUT_ONLY\n",
    "height = 15\n",
    "width = 15\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "distortion_names = (\"k1\", \"k2\", \"p1\", \"k3\", \"k4\", \"p2\")\n",
    "distortion_min = (0.01, 0.001, 0.01, 0.001, -0.05, -0.05)\n",
    "distortion_max = (0.05, 0.05, 0.05, 0.05, 0.05, 0.05)\n",
    "fig = make_subplots(rows=2, cols=3, vertical_spacing=0.1, subplot_titles=distortion_names)\n",
    "\n",
    "num_steps = 19\n",
    "all_steps = []\n",
    "for i in range(len(distortion_names)):\n",
    "    for step in torch.linspace(distortion_min[i], distortion_max[i], num_steps):\n",
    "        distortion_params = torch.zeros(6)\n",
    "        distortion_params[i] = step\n",
    "\n",
    "        from nerfstudio.cameras import camera_utils\n",
    "\n",
    "        coords = torch.meshgrid(torch.linspace(-1, 1, height), torch.linspace(-1, 1, width), indexing=\"ij\")\n",
    "        coords = torch.stack(coords, dim=-1)\n",
    "\n",
    "        coords = camera_utils.radial_and_tangential_undistort(coords, distortion_params)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=coords[..., 0].flatten(),\n",
    "                y=coords[..., 1].flatten(),\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                ),\n",
    "                visible=False,\n",
    "            ),\n",
    "            row=i % 2 + 1,\n",
    "            col=i // 2 + 1,\n",
    "        )\n",
    "\n",
    "    fig.data[num_steps * i + num_steps // 2].visible = True\n",
    "\n",
    "# Create and add slider\n",
    "steps = []\n",
    "for i in range(num_steps):\n",
    "    step = dict(method=\"update\", args=[{\"visible\": [False] * len(fig.data)}], label=\"\")\n",
    "    for d in range(len(distortion_names)):\n",
    "        step[\"args\"][0][\"visible\"][num_steps * d + i] = True\n",
    "    steps.append(step)\n",
    "\n",
    "sliders = [\n",
    "    dict(\n",
    "        active=num_steps // 2,\n",
    "        pad={\"t\": 10},\n",
    "        steps=steps,\n",
    "        len=0.5,\n",
    "        x=0.5,\n",
    "        xanchor=\"center\",\n",
    "    )\n",
    "]\n",
    "\n",
    "webdocs_layout = go.Layout(\n",
    "    height=600,\n",
    "    sliders=sliders,\n",
    "    margin=dict(r=0, b=0, l=0, t=20),\n",
    "    hovermode=False,\n",
    "    showlegend=False,\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"#a3a3a3\", size=18),\n",
    ")\n",
    "fig.for_each_yaxis(lambda x: x.update(range=[-1.3, 1.3], constrain=\"domain\", showgrid=False, visible=False))\n",
    "fig.for_each_xaxis(lambda x: x.update(scaleanchor=\"y\", scaleratio=1, showgrid=False, visible=False))\n",
    "fig.update_layout(webdocs_layout)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

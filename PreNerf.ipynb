{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hucarlos08/Nerf-Geo/blob/main/PreNerf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtyzGfkpXaZq"
      },
      "source": [
        "## Introduction: The 3D Revolution and Its Neural Future\n",
        "\n",
        "In a world where 3D models are becoming as ubiquitous as 2D images, understanding how we represent and interact with three-dimensional spaces is more critical than ever. From designing complex machinery in CAD software to simulating the behavior of structures under stress, or even immersing ourselves in virtual and augmented reality experiences, 3D representation is the backbone of countless engineering applications.\n",
        "\n",
        "But traditional methods for representing 3D objects, like meshes and point clouds, have their limitations. They can be cumbersome, computationally expensive, and struggle to capture the nuances of complex shapes and scenes. This is where Neural Radiance Fields (NeRF), a groundbreaking approach leveraging the power of neural networks, steps in.\n",
        "\n",
        "NeRF has revolutionized the way we think about 3D representation, offering a more flexible, efficient, and photorealistic way to capture and recreate the world around us. In this notebook, we'll embark on a journey to understand the core concepts that underpin this exciting technology. We'll start with the fundamentals of 3D representation, explore how cameras capture light, delve into the magic of rendering, and get a taste of the incredible capabilities of neural networks. By the end, you'll have a solid grasp of the key ideas that make NeRF tick, setting the stage for deeper exploration into its technical intricacies.\n",
        "\n",
        "So, buckle up and get ready to dive into the fascinating world of 3D representation and its neural future!\n",
        "\n",
        "**In this notebook, we'll cover the following:**\n",
        "\n",
        "1. **Representing the 3D World:** Exploring different ways to represent objects in 3D.\n",
        "2. **Capturing Light: The Pinhole Camera Model:** Understanding how cameras capture 3D scenes.\n",
        "3. **Generating Images: Rendering:** Learning how to create images from 3D data.\n",
        "4. **Neural Networks: Our Universal Tool:** Discovering the power of neural networks for complex tasks.\n",
        "5. **View Synthesis: The NeRF Challenge:**  Understanding the problem NeRF solves and how it differs from traditional methods.\n",
        "6. **NeRF Sneak Peek:** A glimpse into the inner workings and incredible results of NeRF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ3lAF3U_vGN"
      },
      "source": [
        "## But first, necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBbOtfr3_uXV"
      },
      "outputs": [],
      "source": [
        "!pip install meshio open3d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btzTWo7opMJ1"
      },
      "source": [
        "\n",
        "\n",
        "# Representing the 3D World: Beyond Lines and Dots\n",
        "\n",
        "In the digital realm, representing three-dimensional objects accurately and efficiently is a fundamental challenge. Engineering applications, from CAD modeling to virtual reality simulations, rely heavily on our ability to capture and manipulate 3D data. Let's explore some common ways to represent 3D objects and their trade-offs:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HFURevuBg5c"
      },
      "source": [
        "## Meshes: Connecting the Dots\n",
        "\n",
        "- **The Concept:** Imagine wrapping a wireframe around an object, forming a network of interconnected triangles. Each triangle is defined by three points called vertices, and the entire collection of triangles forms a mesh.\n",
        "- **Applications:** Meshes are widely used in computer graphics and engineering due to their flexibility and ability to represent complex shapes.\n",
        "- **Limitations:**\n",
        "     - **Sharpness:** Meshes struggle to represent sharp edges or fine details accurately, requiring many tiny triangles.\n",
        "     - **Complexity:** Complex models can have millions of triangles, making them computationally expensive to manipulate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fWC-TZn_m_A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import meshio\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/empet/Datasets/master/hand.off';\n",
        "mymesh = meshio.read('hand.off')\n",
        "verts = mymesh.points\n",
        "faces = mymesh.cells_dict['triangle']\n",
        "x, y, z  = verts.T\n",
        "i, j, k = faces.T\n",
        "\n",
        "#plot surface triangulation\n",
        "tri_vertices = verts[faces]\n",
        "Xe = []\n",
        "Ye = []\n",
        "Ze = []\n",
        "for T in tri_vertices:\n",
        "    Xe += [T[k%3][0] for k in range(4)] + [ None]\n",
        "    Ye += [T[k%3][1] for k in range(4)] + [ None]\n",
        "    Ze += [T[k%3][2] for k in range(4)] + [ None]\n",
        "\n",
        "\n",
        "fig = make_subplots(\n",
        "          rows=1, cols=1,\n",
        "          subplot_titles=('3d Mesh', 'Mesh3d with vertex intensities', 'Mesh3d with cell intensities'),\n",
        "          horizontal_spacing=0.02,\n",
        "          specs=[[{\"type\": \"scene\"}]])\n",
        "\n",
        "fig.add_trace(go.Scatter3d(x=Xe,\n",
        "                     y=Ye,\n",
        "                     z=Ze,\n",
        "                     mode='lines',\n",
        "                     name='',\n",
        "                     line=dict(color= 'rgb(40,40,40)', width=0.5)), 1, 1)\n",
        "\n",
        "\n",
        "fig.update_layout(width=600, height=600, font_size=10)\n",
        "fig.update_scenes(camera_eye_x=1.45, camera_eye_y=1.45, camera_eye_z=1.45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klDE-l74_m_C"
      },
      "source": [
        "## Point Clouds: A Scattered Representation\n",
        "\n",
        "[Image of a 3D point cloud model]\n",
        "\n",
        "* **The Concept:** A point cloud is simply a collection of points in 3D space, each with coordinates (x, y, z). Imagine a swarm of fireflies representing the surface of an object.\n",
        "* **Applications:** Point clouds are often generated from LiDAR (Light Detection and Ranging) scans, which measure distances to objects using lasers.\n",
        "* **Limitations:**\n",
        "    * **No Connectivity:** Point clouds lack information about how points are connected, making it difficult to distinguish the object's surface from empty space.\n",
        "    * **Rendering:** Creating realistic images from point clouds is challenging due to the lack of surface information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egWijRk6_m_D"
      },
      "outputs": [],
      "source": [
        "import open3d as o3d\n",
        "\n",
        "#draw a point cloud with default parameter\n",
        "dataset = o3d.data.PLYPointCloud()\n",
        "office = o3d.io.read_point_cloud(dataset.path)\n",
        "o3d.visualization.draw_plotly([office])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G83ZQ7XW_m_D"
      },
      "source": [
        "## Volumetric Representation: Filling the Space\n",
        "\n",
        "* **The Concept:**  Imagine dividing 3D space into tiny cubes called voxels (like 3D pixels). Each voxel stores information about the density and color of the material it represents.\n",
        "* **Advantages:**\n",
        "    * **Continuous:** Volumetric representations capture the continuous nature of real-world objects, unlike discrete meshes or points.\n",
        "    * **Implicit Surfaces:**  We can define surfaces implicitly as regions where density crosses a certain threshold.\n",
        "* **Relevance to NeRF:** Neural Radiance Fields leverage this volumetric representation, learning the density and color of each point in space. This allows for incredibly detailed and realistic 3D scenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hN1CslA_m_D"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "vol = io.imread(\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/attention-mri.tif\")\n",
        "volume = vol.T\n",
        "r, c = volume[0].shape\n",
        "\n",
        "# Define frames\n",
        "import plotly.graph_objects as go\n",
        "nb_frames = 68\n",
        "\n",
        "fig = go.Figure(frames=[go.Frame(data=go.Surface(\n",
        "    z=(6.7 - k * 0.1) * np.ones((r, c)),\n",
        "    surfacecolor=np.flipud(volume[67 - k]),\n",
        "    cmin=0, cmax=200\n",
        "    ),\n",
        "    name=str(k) # you need to name the frame for the animation to behave properly\n",
        "    )\n",
        "    for k in range(nb_frames)])\n",
        "\n",
        "# Add data to be displayed before animation starts\n",
        "fig.add_trace(go.Surface(\n",
        "    z=6.7 * np.ones((r, c)),\n",
        "    surfacecolor=np.flipud(volume[67]),\n",
        "    colorscale='Gray',\n",
        "    cmin=0, cmax=200,\n",
        "    colorbar=dict(thickness=20, ticklen=4)\n",
        "    ))\n",
        "\n",
        "\n",
        "def frame_args(duration):\n",
        "    return {\n",
        "            \"frame\": {\"duration\": duration},\n",
        "            \"mode\": \"immediate\",\n",
        "            \"fromcurrent\": True,\n",
        "            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n",
        "        }\n",
        "\n",
        "sliders = [\n",
        "            {\n",
        "                \"pad\": {\"b\": 10, \"t\": 60},\n",
        "                \"len\": 0.9,\n",
        "                \"x\": 0.1,\n",
        "                \"y\": 0,\n",
        "                \"steps\": [\n",
        "                    {\n",
        "                        \"args\": [[f.name], frame_args(0)],\n",
        "                        \"label\": str(k),\n",
        "                        \"method\": \"animate\",\n",
        "                    }\n",
        "                    for k, f in enumerate(fig.frames)\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "\n",
        "# Layout\n",
        "fig.update_layout(\n",
        "         title='Slices in volumetric data',\n",
        "         width=600,\n",
        "         height=600,\n",
        "         scene=dict(\n",
        "                    zaxis=dict(range=[-0.1, 6.8], autorange=False),\n",
        "                    aspectratio=dict(x=1, y=1, z=1),\n",
        "                    ),\n",
        "         updatemenus = [\n",
        "            {\n",
        "                \"buttons\": [\n",
        "                    {\n",
        "                        \"args\": [None, frame_args(50)],\n",
        "                        \"label\": \"&#9654;\", # play symbol\n",
        "                        \"method\": \"animate\",\n",
        "                    },\n",
        "                    {\n",
        "                        \"args\": [[None], frame_args(0)],\n",
        "                        \"label\": \"&#9724;\", # pause symbol\n",
        "                        \"method\": \"animate\",\n",
        "                    },\n",
        "                ],\n",
        "                \"direction\": \"left\",\n",
        "                \"pad\": {\"r\": 10, \"t\": 70},\n",
        "                \"type\": \"buttons\",\n",
        "                \"x\": 0.1,\n",
        "                \"y\": 0,\n",
        "            }\n",
        "         ],\n",
        "         sliders=sliders\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
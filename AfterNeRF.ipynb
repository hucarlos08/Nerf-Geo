{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlqA4oz77XXuIKhua2xm8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hucarlos08/Nerf-Geo/blob/main/AfterNeRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Satellite Images\n",
        "\n",
        "Several works have applied the principles of NeRF using satellite images to achieve impressive results in 3D reconstruction and photogrammetry.\n",
        "\n",
        "1. **[Multi-view Satellite Photogrammetry with Neural Radiance Fields](https://www.esa.int/gsp/ACT/projects/multiviewnerf/)**\n",
        "\n",
        "   The objective of this project is to create a volumetric 3D color representation of a scene using a collection of satellite images. By leveraging NeRF, the project aims to generate detailed and accurate 3D models from multi-view satellite imagery, enhancing the capabilities of satellite photogrammetry.\n",
        "\n",
        "   | ![2d-train](https://imgur.com/M1VZa39.png) |\n",
        "   | :---: |\n",
        "   | **Figure 1**: NeRF applied to satellite imagery for 3D volumetric representation. |\n",
        "\n",
        "2. **[Shadow Neural Radiance Fields (S-NeRF)](https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Derksen_Shadow_Neural_Radiance_Fields_for_Multi-View_Satellite_Photogrammetry_CVPRW_2021_paper.html)**\n",
        "\n",
        "   The S-NeRF methodology not only performs novel view synthesis and complete 3D shape estimation but also enables shadow detection, albedo synthesis, and transient object filtering without any explicit shape supervision. This approach allows for more comprehensive and detailed scene reconstructions from satellite images.\n",
        "\n",
        "   | ![2d-train](https://imgur.com/PBN5Jm6.png) |\n",
        "   | :---: |\n",
        "   | **Figure 2**: S-NeRF methodology applied to satellite imagery for enhanced photogrammetry, including shadow detection and albedo synthesis. |\n",
        "\n",
        "### Summary\n",
        "\n",
        "The application of Neural Radiance Fields (NeRF) in satellite imagery has opened up new possibilities for 3D reconstruction and photogrammetry. By using advanced techniques such as S-NeRF, researchers can achieve more accurate and detailed models, improving the quality and capabilities of satellite-based analysis.\n",
        "\n",
        "These advancements highlight the versatility of NeRF and its potential to revolutionize various fields, including remote sensing and Earth observation.\n",
        "\n",
        "### References\n",
        "\n",
        "- [Multi-view Satellite Photogrammetry with Neural Radiance Fields](https://www.esa.int/gsp/ACT/projects/multiviewnerf/)\n",
        "- [Shadow Neural Radiance Fields (S-NeRF)](https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Derksen_Shadow_Neural_Radiance_Fields_for_Multi-View_Satellite_Photogrammetry_CVPRW_2021_paper.html)\n"
      ],
      "metadata": {
        "id": "1-_u1ZNUTMMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving Computational Efficiency of NeRF\n",
        "\n",
        "Several projects and research papers aim to improve the computational time and cost associated with Neural Radiance Fields (NeRF). These approaches introduce novel techniques to enhance efficiency, scalability, and performance.\n",
        "\n",
        "1. **[NeRF++](https://arxiv.org/abs/2010.07492)**\n",
        "\n",
        "   NeRF++ proposes to model the background with a separate NeRF to handle unbounded scenes. This approach effectively separates the foreground and background, allowing for better handling of scenes with infinite extents.\n",
        "\n",
        "\n",
        "2. **[DeRF](https://ubc-vision.github.io/derf/)**\n",
        "\n",
        "   DeRF decomposes the scene into \"soft Voronoi diagrams\" to leverage memory-efficient architectures. This technique partitions the scene into regions that can be processed independently, reducing memory overhead and improving scalability.\n",
        "\n",
        "3. **[AutoInt](https://www.computationalimaging.org/publications/automatic-integration/)**\n",
        "\n",
        "   AutoInt accelerates rendering significantly by learning the volume integral directly. This method bypasses the need for explicit numerical integration, resulting in faster and more efficient rendering. It is a general approach that can be applied to various volumetric rendering tasks.\n",
        "\n",
        "\n",
        "4. **[JaxNeRF](https://github.com/google-research/google-research/tree/master/jaxnerf)**\n",
        "\n",
        "   JaxNeRF utilizes [JAX](https://github.com/google/jax) to drastically accelerate training, reducing the training time from days to hours. JAX's powerful automatic differentiation and XLA compilation capabilities enable efficient computation and scaling on modern hardware.\n",
        "\n",
        "\n",
        "### Summary\n",
        "\n",
        "These advancements demonstrate the ongoing efforts to improve the efficiency and scalability of NeRF. By introducing novel techniques such as separate modeling of foreground and background, memory-efficient scene decomposition, direct learning of volume integrals, and leveraging modern computational libraries like JAX, researchers are pushing the boundaries of what NeRF can achieve.\n",
        "\n",
        "### References\n",
        "\n",
        "- [NeRF++: Analyzing and Improving Neural Radiance Fields](https://arxiv.org/abs/2010.07492)\n",
        "- [DeRF: Decomposed Radiance Fields](https://ubc-vision.github.io/derf/)\n",
        "- [AutoInt: Automatic Integration](https://www.computationalimaging.org/publications/automatic-integration/)\n",
        "- [JaxNeRF: Accelerated Neural Radiance Fields](https://github.com/google-research/google-research/tree/master/jaxnerf)\n"
      ],
      "metadata": {
        "id": "34U5MM5XTnYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Neural Radiance Fields for Unconstrained Photo Collections\n",
        "\n",
        "Originally presented in [NeRF in the Wild (NeRF-W)](https://nerf-w.github.io/), this approach addresses many of the limitations associated with the original NeRF. NeRF-W is capable of constructing impressive 3D environments from a diverse set of images that vary significantly over time.\n",
        "\n",
        "**Key Features:**\n",
        "- Handles variations in lighting, weather, and seasonal changes.\n",
        "- Incorporates additional metadata such as camera parameters to improve the reconstruction quality.\n",
        "- Utilizes a robust optimization framework to deal with the noise and inconsistencies in unconstrained photo collections.\n",
        "\n",
        "**Implementation:**\n",
        "- There is a [free implementation](https://github.com/kwea123/nerf_pl) available in PyTorch.\n",
        "\n",
        "**Results:**\n",
        "\n",
        "| ![NeRF in the Wild](https://imgur.com/FEoZOcj.png) |\n",
        "| :---: |\n",
        "| **Figure 1**: NeRF in the Wild concept - reconstructing 3D scenes from unconstrained photo collections. |\n",
        "\n",
        "| ![NeRF in the Wild Results](https://imgur.com/ttdunLr.png) |\n",
        "| :---: |\n",
        "| **Figure 2**: Example results from NeRF in the Wild - showcasing the ability to handle diverse and varying input images. |\n",
        "\n",
        "### Summary\n",
        "\n",
        "NeRF in the Wild extends the capabilities of the original NeRF by enabling 3D scene reconstruction from unconstrained photo collections. This approach significantly enhances the robustness and applicability of NeRF, making it suitable for real-world scenarios where input images are not controlled and can vary widely.\n",
        "\n",
        "### References\n",
        "\n",
        "- [NeRF in the Wild (NeRF-W)](https://nerf-w.github.io/)\n",
        "- [NeRF-W PyTorch Implementation](https://github.com/kwea123/nerf_pl)"
      ],
      "metadata": {
        "id": "gW72XF3fT6Wj"
      }
    }
  ]
}